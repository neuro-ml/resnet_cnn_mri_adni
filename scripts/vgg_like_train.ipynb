{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook for reproduce paper results\n",
    "\n",
    "##### content\n",
    "\n",
    "- [Batch iteration functions](#Batch-iteration-functions)\n",
    "- [Train functions](#Train-functions)\n",
    "- [Network architecture](#network-architecture)\n",
    "- [Cross_validation function](#cross-validation)\n",
    "- [Cross-validation one_vs_one - run](#Cross-validation-one_vs_one)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import traceback\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "from tqdm import *\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "from lasagne.layers import InputLayer\n",
    "from lasagne.layers.dnn import Conv3DDNNLayer\n",
    "from lasagne.layers.dnn import Pool3DDNNLayer\n",
    "from lasagne.layers import BatchNormLayer\n",
    "from lasagne.layers import NonlinearityLayer\n",
    "from lasagne.layers import ElemwiseSumLayer\n",
    "from lasagne.layers import DenseLayer\n",
    "from lasagne.nonlinearities import rectify, softmax, identity\n",
    "from lasagne.layers import set_all_param_values\n",
    "from lasagne.layers import DropoutLayer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH_TO_REP = 'data/'  # adni_data\n",
    "\n",
    "inp_shape = (None, 1, 110, 110, 110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_var = T.TensorType('float32', (False,) * 5)('inputs')\n",
    "target_var = T.ivector('targets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch iteration functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import iterate_minibatches, iterate_minibatches_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_functions(nn, updates_method=lasagne.updates.nesterov_momentum,\n",
    "                        _lr=0.00001):\n",
    "    \"\"\"\n",
    "    Return functions for training, validation network and predicting answers.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    nn : lasagne.Layer\n",
    "        network last layer\n",
    "\n",
    "    updates_method : function\n",
    "        like in lasagne.objectives or function from there\n",
    "\n",
    "    _lr : float\n",
    "        learning rate which relate with the updates_method\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_fn : theano.function\n",
    "        Train network function.\n",
    "    val_fn : theano.function\n",
    "        Validation function.\n",
    "    pred_fn : theano.function\n",
    "        Function for get predicts from network.\n",
    "    \"\"\"\n",
    "    prediction = lasagne.layers.get_output(nn)\n",
    "    loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "    loss = loss.mean()\n",
    "    params = lasagne.layers.get_all_params(nn, trainable=True)\n",
    "    updates = updates_method(loss, params, learning_rate=_lr)\n",
    "\n",
    "    test_prediction = lasagne.layers.get_output(nn, deterministic=True)\n",
    "    test_loss = lasagne.objectives.categorical_crossentropy(test_prediction,\n",
    "                                                            target_var)\n",
    "    test_loss = test_loss.mean()\n",
    "\n",
    "    train_fn = theano.function([input_var, target_var], loss, updates=updates)\n",
    "    val_fn = theano.function([input_var, target_var], test_loss)\n",
    "    pred_fn = theano.function([input_var], test_prediction)\n",
    "\n",
    "    return train_fn, val_fn, pred_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(train_fn, val_fn, test_fn,\n",
    "          X_train, y_train,\n",
    "          X_test, y_test,\n",
    "          LABEL_1, LABEL_2,  # labels of the y.\n",
    "          num_epochs=100, batchsize=5,\n",
    "          dict_of_paths={'output': '1.txt', 'picture': '1.png',\n",
    "                         'report': 'report.txt'},\n",
    "          report='''trained next architecture, used some\n",
    "                    optimizstion method with learning rate...''',\n",
    "          architecture='nn=...'):\n",
    "    \"\"\"\n",
    "    Iterate minibatches on train subset and validate results on test subset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_fn : theano.function\n",
    "        Train network function.\n",
    "    val_fn : theano.function\n",
    "        Validation network function.\n",
    "    test_fn : theano.function\n",
    "        Function for get predicts from network.\n",
    "    X_train : numpy array\n",
    "        X train subset.\n",
    "    y_train : numpy array\n",
    "        Y train subset.\n",
    "    X_test : numpy array\n",
    "        X test subset.\n",
    "    y_test : numpy array\n",
    "        Y test subset.\n",
    "    LABEL_1 : {'AD', 'LMCI', 'EMCI', 'Normal'}\n",
    "        String label for target == 0.\n",
    "    LABEL_2 : {'AD', 'LMCI', 'EMCI', 'Normal'}\n",
    "        String label for target == 1.\n",
    "    dict_of_paths : dictionary\n",
    "        Names of files to store results.\n",
    "    report : string\n",
    "        Some comments which will saved into report after ending of training.\n",
    "    num_epochs : integer\n",
    "        Number of epochs for all of the experiments. Default is 100.\n",
    "    batchsize : integer\n",
    "        Batchsize for network training. Default is 5.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tr_losses : numpy.array\n",
    "        Array with loss values on train.\n",
    "    val_losses : numpy.array\n",
    "        Array with loss values on test.\n",
    "    val_accs : numpy.array\n",
    "        Array with accuracy values on test.\n",
    "    rocs : numpy.array\n",
    "        Array with roc auc values on test.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    eps = []\n",
    "    tr_losses = []\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "    rocs = []\n",
    "\n",
    "    FILE_PATH = dict_of_paths['output']\n",
    "    PICTURE_PATH = dict_of_paths['picture']\n",
    "    REPORT_PATH = dict_of_paths['report']\n",
    "\n",
    "    # here we written outputs on each step (val and train losses, accuracy, auc)\n",
    "    with open(FILE_PATH, 'w') as f:\n",
    "        f.write('\\n----------\\n\\n' + str(datetime.datetime.now())[:19])\n",
    "        f.write('\\n' + LABEL_1 + '-' + LABEL_2 + '\\n')\n",
    "        f.close()\n",
    "\n",
    "    # starting training\n",
    "    print(\"Starting training...\", flush=True)\n",
    "    den = X_train.shape[0] / batchsize\n",
    "    for epoch in range(num_epochs):\n",
    "        train_err = 0\n",
    "        train_batches = 0\n",
    "        start_time = time.time()\n",
    "        for batch in iterate_minibatches_train(X_train, y_train, batchsize,\n",
    "                                               shuffle=True):\n",
    "            inputs, targets = batch\n",
    "            train_err += train_fn(inputs, targets)\n",
    "            train_batches += 1\n",
    "\n",
    "        val_err = 0\n",
    "        val_batches = 0\n",
    "        preds = []\n",
    "        targ = []\n",
    "        for batch in iterate_minibatches(X_test, y_test, batchsize,\n",
    "                                         shuffle=False):\n",
    "            inputs, targets = batch\n",
    "            err = val_fn(inputs, targets)\n",
    "            val_err += err\n",
    "            val_batches += 1\n",
    "            out = test_fn(inputs)\n",
    "            [preds.append(i) for i in out]\n",
    "            [targ.append(i) for i in targets]\n",
    "\n",
    "        preds_tst = np.array(preds).argmax(axis=1)\n",
    "        ##\n",
    "        ## output\n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(epoch + 1,\n",
    "                                                   num_epochs,\n",
    "                                                   time.time() - start_time),\n",
    "              flush=True)\n",
    "        print(\"  training loss:\\t\\t{:.7f}\".format(train_err / train_batches),\n",
    "              flush=True)\n",
    "        print(\"  validation loss:\\t\\t{:.7f}\".format(val_err / val_batches),\n",
    "              flush=True)\n",
    "        print('  validation accuracy:\\t\\t{:.7f}'.format(\n",
    "            accuracy_score(np.array(targ),\n",
    "                           preds_tst)), flush=True)\n",
    "        print('Confusion matrix for test:', flush=True)\n",
    "        print(confusion_matrix(np.array(targ), np.array(preds).argmax(axis=1)),\n",
    "              flush=True)\n",
    "        rcs = roc_auc_score(np.array(targ), np.array(preds)[:, 1])\n",
    "        sys.stderr.write('Pairwise ROC_AUCs: ' + str(rcs))\n",
    "        print('')\n",
    "\n",
    "        with open(FILE_PATH, 'a') as f:\n",
    "            f.write(\"\\nEpoch {} of {} took {:.3f}s\".format(epoch + 1,\n",
    "                                                           num_epochs,\n",
    "                                                           time.time() - start_time))\n",
    "            f.write(\n",
    "                \"\\n training loss:\\t\\t{:.7f}\".format(train_err / train_batches))\n",
    "            f.write(\n",
    "                \"\\n validation loss:\\t\\t{:.7f}\".format(val_err / val_batches))\n",
    "            f.write('\\n validation accuracy:\\t\\t{:.7f}'.format(\n",
    "                accuracy_score(np.array(targ),\n",
    "                               np.array(preds).argmax(axis=1))))\n",
    "\n",
    "            f.write('\\n Pairwise ROC_AUCs:' + str(rcs) + '\\n')\n",
    "            f.close()\n",
    "        ## output\n",
    "        ## saving results\n",
    "        eps.append(epoch + 1)\n",
    "        tr_losses.append(train_err / train_batches)\n",
    "        val_losses.append(val_err / val_batches)\n",
    "        val_accs.append(\n",
    "            accuracy_score(np.array(targ), np.array(preds).argmax(axis=1)))\n",
    "        rocs.append(rcs)\n",
    "\n",
    "    print('ended!')\n",
    "\n",
    "    ### and save plots\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.title('Loss ' + LABEL_1 + ' vs ' + LABEL_2)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylim((0, 3))\n",
    "    plt.ylabel('Loss')\n",
    "    plt.plot(eps, tr_losses, label='train')\n",
    "    plt.plot(eps, val_losses, label='validation')\n",
    "    plt.legend(loc=0)\n",
    "    #\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.title('Accuracy ' + LABEL_1 + ' vs ' + LABEL_2)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.plot(eps, val_accs, label='validation accuracy')\n",
    "    plt.legend(loc=0)\n",
    "    #\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.title('AUC ' + LABEL_1 + ' vs ' + LABEL_2)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('AUC')\n",
    "    plt.plot(eps, np.array(rocs), label='validation auc')\n",
    "    plt.legend(loc=0)\n",
    "    #\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.title('architecture')\n",
    "    plt.axis('off')\n",
    "    plt.text(0, -0.1, architecture, fontsize=7, )\n",
    "    plt.savefig(PICTURE_PATH)\n",
    "    ###########\n",
    "\n",
    "    # write that trainig was ended\n",
    "    with open(FILE_PATH, 'a') as f:\n",
    "        f.write('\\nended at ' + str(datetime.datetime.now())[:19] + '\\n \\n')\n",
    "        f.close()\n",
    "\n",
    "    # write report\n",
    "    with open(REPORT_PATH, 'a') as f:\n",
    "        f.write(\n",
    "            '\\n классификация ' + LABEL_1 + ' vs ' + LABEL_2 + '\\n' + report)\n",
    "        #         f.write(architecture)\n",
    "        f.write('final results are:')\n",
    "        f.write('\\n tr_loss: ' + str(tr_losses[-1]) + '\\n val_loss: ' + \\\n",
    "                str(val_losses[-1]) + '\\n val_acc; ' + str(val_accs[-1]) + \\\n",
    "                '\\n val_roc_auc: ' + str(rocs[-1]))\n",
    "        f.write('\\nresults has been saved in files:\\n')\n",
    "        f.write(FILE_PATH + '\\n')\n",
    "        f.write(PICTURE_PATH + '\\n')\n",
    "        f.write('\\n ___________________ \\n\\n\\n')\n",
    "        f.close()\n",
    "\n",
    "    return tr_losses, val_losses, val_accs, rocs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_net():\n",
    "    \"\"\"Method for VGG like net Building.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    nn : lasagne.layer\n",
    "        Network.\n",
    "    \"\"\"\n",
    "    nn = InputLayer(inp_shape, input_var=input_var)\n",
    "\n",
    "    nn = Conv3DDNNLayer(nn, 8, 3)\n",
    "    nn = Conv3DDNNLayer(nn, 8, 3, nonlinearity=identity)\n",
    "    nn = NonlinearityLayer(nn)\n",
    "    nn = Pool3DDNNLayer(nn, 2)\n",
    "\n",
    "    nn = Conv3DDNNLayer(nn, 16, 3)\n",
    "    nn = Conv3DDNNLayer(nn, 16, 3, nonlinearity=identity)\n",
    "    nn = NonlinearityLayer(nn)\n",
    "    nn = Pool3DDNNLayer(nn, 2)\n",
    "\n",
    "    nn = Conv3DDNNLayer(nn, 32, 3)\n",
    "    nn = Conv3DDNNLayer(nn, 32, 3)\n",
    "    nn = Conv3DDNNLayer(nn, 32, 3, nonlinearity=identity)\n",
    "    nn = NonlinearityLayer(nn)\n",
    "    nn = Pool3DDNNLayer(nn, 2)\n",
    "\n",
    "    nn = Conv3DDNNLayer(nn, 64, 3)\n",
    "    nn = Conv3DDNNLayer(nn, 64, 3)\n",
    "    nn = Conv3DDNNLayer(nn, 64, 3, nonlinearity=identity)\n",
    "    nn = NonlinearityLayer(nn)\n",
    "    nn = Pool3DDNNLayer(nn, 2)\n",
    "\n",
    "    nn = DenseLayer(nn, num_units=128)\n",
    "    nn = BatchNormLayer(nn)\n",
    "    nn = DropoutLayer(nn, p=0.7)\n",
    "\n",
    "    nn = DenseLayer(nn, num_units=64)\n",
    "\n",
    "    nn = DenseLayer(nn, num_units=2,\n",
    "                    nonlinearity=lasagne.nonlinearities.softmax)\n",
    "    return nn\n",
    "\n",
    "\n",
    "# writing architecture in report\n",
    "architecture = '''\n",
    "nn = InputLayer(inp_shape, input_var=input_var)\n",
    "\n",
    "nn = Conv3DDNNLayer(nn, 8, 3)\n",
    "nn = Conv3DDNNLayer(nn, 8, 3, nonlinearity=identity)\n",
    "nn = NonlinearityLayer(nn)\n",
    "nn = Pool3DDNNLayer(nn, 2)\n",
    "\n",
    "nn = Conv3DDNNLayer(nn, 16, 3)\n",
    "nn = Conv3DDNNLayer(nn, 16, 3, nonlinearity=identity)\n",
    "nn = NonlinearityLayer(nn)\n",
    "nn = Pool3DDNNLayer(nn, 2)\n",
    "\n",
    "nn = Conv3DDNNLayer(nn, 32, 3)\n",
    "nn = Conv3DDNNLayer(nn, 32, 3)\n",
    "nn = Conv3DDNNLayer(nn, 32, 3, nonlinearity=identity)\n",
    "nn = NonlinearityLayer(nn)\n",
    "nn = Pool3DDNNLayer(nn, 2)\n",
    "\n",
    "nn = Conv3DDNNLayer(nn, 64, 3)\n",
    "nn = Conv3DDNNLayer(nn, 64, 3)\n",
    "nn = Conv3DDNNLayer(nn, 64, 3, nonlinearity=identity)\n",
    "nn = NonlinearityLayer(nn)\n",
    "nn = Pool3DDNNLayer(nn, 2)\n",
    "\n",
    "nn = DenseLayer(nn, num_units=128)\n",
    "nn = BatchNormLayer(nn)\n",
    "nn = DropoutLayer(nn, p=0.7)\n",
    "\n",
    "nn = DenseLayer(nn, num_units=64)\n",
    "\n",
    "nn = DenseLayer(nn, num_units=2, nonlinearity=lasagne.nonlinearities.softmax)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnd_states = [14, 11, 1993, 19931411, 14111993]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_cross_validation(LABEL_1, LABEL_2, results_folder):\n",
    "    \"\"\"\n",
    "    Method for cross-validation.\n",
    "    Takes two labels, reading data, prepair data with this labels for trainig.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    LABEL_1 : {'AD', 'LMCI', 'EMCI', 'Normal'}\n",
    "        String label for target == 0.\n",
    "    LABEL_2 : {'AD', 'LMCI', 'EMCI', 'Normal'}\n",
    "        String label for target == 1.\n",
    "    results_folder : string\n",
    "        Folder to store results.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(results_folder):\n",
    "        os.makedirs(results_folder)\n",
    "\n",
    "    # reading data\n",
    "    gc.collect()\n",
    "    metadata = pd.read_csv(PATH_TO_REP + 'metadata.csv')\n",
    "    smc_mask = (\n",
    "    (metadata.Label == LABEL_1) | (metadata.Label == LABEL_2)).values.astype(\n",
    "        'bool')\n",
    "    y = (metadata[smc_mask].Label == LABEL_1).astype(np.int32).values\n",
    "    data = np.zeros((smc_mask.sum(), 1, 110, 110, 110), dtype='float32')\n",
    "    # into memory\n",
    "    for it, im in tqdm(enumerate(metadata[smc_mask].Path.values),\n",
    "                       total=smc_mask.sum(), desc='Reading MRI to memory'):\n",
    "        mx = nib.load(im).get_data().max(axis=0).max(axis=0).max(axis=0)\n",
    "        data[it, 0, :, :, :] = np.array(nib.load(im).get_data()) / mx\n",
    "\n",
    "    # loop by random states (different splitting)\n",
    "    for i in range(len(rnd_states)):\n",
    "        counter = 1\n",
    "        cv_results = []\n",
    "        skf = StratifiedKFold(y, n_folds=5, random_state=rnd_states[i])\n",
    "\n",
    "        for tr, ts in skf:\n",
    "            X_train = data[tr]\n",
    "            X_test = data[ts]\n",
    "            y_train = y[tr]\n",
    "            y_test = y[ts]\n",
    "            # creating folder for random states\n",
    "            rnd_state_folder = results_folder + 'rnd_state_' + str(i) + '/'\n",
    "            if not os.path.exists(rnd_state_folder):\n",
    "                os.makedirs(rnd_state_folder)\n",
    "\n",
    "            dict_of_paths = {\n",
    "                'output': rnd_state_folder + 'Exp_CV_' + str(\n",
    "                    counter) + '_' + LABEL_1 + '_vs_' + \\\n",
    "                          LABEL_2 + '_.txt',\n",
    "                'picture': rnd_state_folder + 'Exp_CV_' + str(\n",
    "                    counter) + '_' + LABEL_1 + '_vs_' + \\\n",
    "                           LABEL_2 + '_.png',\n",
    "                'report': 'report.txt'\n",
    "            }\n",
    "\n",
    "            report = '\\n' + LABEL_1 + '_vs_' + LABEL_2 + 'cv_fold ' + \\\n",
    "                     str(counter) + ' random state ' + str(i) + \\\n",
    "                     '_\\n' + 'adam, lr=0.000027' + '\\n '\n",
    "            # building net and training\n",
    "            nn = build_net()\n",
    "            train_fn, val_fn, test_fn = get_train_functions(nn,\n",
    "                                                            updates_method=lasagne.updates.adam,\n",
    "                                                            _lr=0.000027)\n",
    "\n",
    "            try:\n",
    "                tr_losses, val_losses, val_accs, rocs = train(train_fn, val_fn,\n",
    "                                                              test_fn, X_train,\n",
    "                                                              y_train, X_test,\n",
    "                                                              y_test, LABEL_1,\n",
    "                                                              LABEL_2,\n",
    "                                                              num_epochs=150,\n",
    "                                                              batchsize=5,\n",
    "                                                              dict_of_paths=dict_of_paths,\n",
    "                                                              report=report,\n",
    "                                                              architecture=architecture)\n",
    "                cv_results.append((tr_losses, val_losses, val_accs, rocs))\n",
    "            except Exception as e:\n",
    "                with open('errors_msg.txt', 'a') as f:\n",
    "                    f.write('Time: ' + str(datetime.datetime.now())[:19] + \\\n",
    "                            '\\n' + str(e) + traceback.format_exc())\n",
    "\n",
    "            counter += 1\n",
    "            # saving network params\n",
    "        #             np.savez('net_weights'+ str(counter) + str(i) +'.npz',\n",
    "        #                      *lasagne.layers.get_all_param_values(nn))\n",
    "\n",
    "        # saving losses, aucs, accuracies\n",
    "        np.savez(results_folder + 'cv_results_' + LABEL_1 + \\\n",
    "                 '_vs_' + LABEL_2 + '_' + str(i) + '.npz', np.array(cv_results))\n",
    "\n",
    "        # plotting mean roc_auc and  with losses by random_state\n",
    "        plt.figure()\n",
    "        plt.plot(np.array(cv_results)[:, 3, :].mean(axis=0))\n",
    "        y1 = np.array(cv_results)[:, 3, :].mean(axis=0) + np.array(cv_results)[\n",
    "                                                          :, 3, :].std(axis=0)\n",
    "        y2 = np.array(cv_results)[:, 3, :].mean(axis=0) - np.array(cv_results)[\n",
    "                                                          :, 3, :].std(axis=0)\n",
    "        plt.fill_between(np.arange(len(y1)), y1, y2, alpha=0.4)\n",
    "        plt.title(\n",
    "            'mean roc auc' + '_' + str(i) + '_ ' + LABEL_1 + ' vs ' + LABEL_2)\n",
    "        plt.ylabel('roc_auc')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.savefig(\n",
    "            rnd_state_folder + 'mean_roc_auc_5_fold_cv_' + LABEL_1 + '_vs_' + LABEL_2 + \\\n",
    "            '_for_rnd_state_' + str(i) + '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation one_vs_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_cross_validation('AD', 'Normal', './results_cnn/ad_vs_norm/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_cross_validation('AD', 'LMCI', './results_cnn/ad_vs_lmci/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_cross_validation('AD', 'EMCI', './results_cnn/ad_vs_emci/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_cross_validation('Normal', 'EMCI', './results_cnn/norm_vs_emci/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_cross_validation('Normal', 'LMCI', './results_cnn/norm_vs_lmci/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_cross_validation('EMCI', 'LMCI', './results_cnn/emci_vs_lmci/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
